{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Shortcuts](https://gist.github.com/kidpixo/f4318f8c8143adee5b40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3L,)\n",
      "\n",
      "[[ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.]]\n",
      "\n",
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "[1 4 6]\n",
      "\n",
      "[1 4 6 1 4 6]\n",
      "\n",
      "[[1 4 6]\n",
      " [1 4 6]]\n"
     ]
    }
   ],
   "source": [
    "## numpy array\n",
    "a = np.array([1, 4, 6])\n",
    "print a.shape\n",
    "print \n",
    "print np.ones((3, 4))\n",
    "print\n",
    "print np.zeros((2, 5))\n",
    "print\n",
    "print np.arange(6).reshape(2, 3)\n",
    "print\n",
    "print a.T\n",
    "print\n",
    "print np.hstack([a, a])\n",
    "print\n",
    "print np.vstack([a, a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "\n",
      "[ 1 16 36]\n"
     ]
    }
   ],
   "source": [
    "## element wise or matrix multiplication\n",
    "print np.dot(a, a)  # or a.dot(a)\n",
    "print \n",
    "print a*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "[1 4 6]\n",
      "a.shape: (3L,)\n",
      "\n",
      "a[np.newaxis] is a 2-d row vector:\n",
      "[[1 4 6]]\n",
      "a[np.newaxis].shape: (1L, 3L)\n",
      "\n",
      "a[np.newaxis].T: is a 2-d column vector:\n",
      "[[1]\n",
      " [4]\n",
      " [6]]\n",
      "a[np.newaxis].T.shape: (3L, 1L)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can convert a 1-d array to a 2-d array with np.newaxis\n",
    "print 'a:'\n",
    "print a\n",
    "print 'a.shape:', a.shape\n",
    "print \n",
    "print 'a[np.newaxis] is a 2-d row vector:'\n",
    "print a[np.newaxis]\n",
    "print 'a[np.newaxis].shape:', a[np.newaxis].shape\n",
    "print\n",
    "\n",
    "print 'a[np.newaxis].T: is a 2-d column vector:'\n",
    "print a[np.newaxis].T\n",
    "print 'a[np.newaxis].T.shape:', a[np.newaxis].T.shape\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse of [[1, 2],[3, 4]]:\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "\n",
      "m.dot(m_inverse):\n",
      "[[  1.00000000e+00   1.11022302e-16]\n",
      " [  0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# numpy provides a ton of other functions for working with matrices\n",
    "m = np.array([[1, 2],[3, 4]])\n",
    "m_inverse = np.linalg.inv(m)\n",
    "print 'inverse of [[1, 2],[3, 4]]:'\n",
    "print m_inverse\n",
    "print\n",
    "\n",
    "print 'm.dot(m_inverse):'\n",
    "print m.dot(m_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a matrix with random entries drawn from a Normal(0, 1) distribution:\n",
      "[[-0.70978938 -0.01719118  0.31941137 -2.26533107]\n",
      " [-1.37745366  1.94998073 -0.56381007 -0.84373759]\n",
      " [ 0.22453858 -0.39137772  0.60550347 -0.68615034]]\n"
     ]
    }
   ],
   "source": [
    "# and for doing all kinds of sciency type stuff.  like generating random numbers:\n",
    "np.random.seed(5678)\n",
    "n = np.random.randn(3, 4)\n",
    "print 'a matrix with random entries drawn from a Normal(0, 1) distribution:'\n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_no_constant:\n",
      "[[-0.92232935  0.27352359 -0.86339625  1.43766044 -1.71379871]\n",
      " [ 0.179322   -0.89138595  2.13005603  0.51898975 -0.41875106]\n",
      " [ 0.34010119 -1.07736609 -1.02314142 -1.02518535  0.40972072]\n",
      " [ 1.18883814  1.01044759  0.3108216  -1.17868611 -0.49526331]\n",
      " [-1.50248369 -0.196458    0.34752922 -0.79200465 -0.31534705]\n",
      " [ 1.73245191 -1.42793626 -0.94376587  0.86823495 -0.95946769]\n",
      " [-1.07074604 -0.06555247 -2.17689578  1.58538804  1.81492637]\n",
      " [-0.73706088  0.77546031  0.42653908 -0.51853723 -0.53045538]\n",
      " [ 1.09620536 -0.69557321  0.03080082  0.25219596 -0.35304303]\n",
      " [-0.93971165  0.04448078  0.04273069  0.4961477  -1.7673568 ]]\n",
      "\n",
      "****** Tests passed! ******\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3333)\n",
    "n_data = 10 # number of data points. i.e. N\n",
    "n_dim = 5   # number of dimensions of each datapoint.  i.e. D\n",
    "\n",
    "betas = np.random.randn(n_dim + 1)\n",
    "\n",
    "X_no_constant = np.random.randn(n_data, n_dim)\n",
    "print 'X_no_constant:'\n",
    "print X_no_constant\n",
    "print \n",
    "\n",
    "# INSERT YOUR CODE HERE!\n",
    "X = np.hstack([np.ones(n_data)[np.newaxis].T, X_no_constant])\n",
    "y = np.dot(X, betas)\n",
    "\n",
    "# Tests:\n",
    "y_expected = np.array([-0.41518357, -9.34696153, 5.08980544, \n",
    "                       -0.26983873, -1.47667864, 1.96580794, \n",
    "                       6.87009791, -2.07784135, -0.7726816, \n",
    "                       -2.74954984])\n",
    "np.testing.assert_allclose(y, y_expected)\n",
    "print '****** Tests passed! ******'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[6 7]\n",
      " [3 1]\n",
      " [4 0]]\n",
      "\n",
      "DataFame version of b:\n",
      "   Weight  Height\n",
      "0       6       7\n",
      "1       3       1\n",
      "2       4       0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[6, 7], [3, 1], [4, 0]])\n",
    "df = pd.DataFrame(data=b,  columns=['Weight', 'Height'])\n",
    "print 'b:'\n",
    "print b\n",
    "print \n",
    "print 'DataFame version of b:'\n",
    "print df\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.dat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baseball.head()\n",
    "# baseball.describe()\n",
    "# baseball.keys()\n",
    "# baseball.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseball.shape: (337, 18)\n",
      "baseball[millionaire_indices].shape: (139, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300</td>\n",
       "      <td>0.272</td>\n",
       "      <td>69</td>\n",
       "      <td>Andre Dawson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.269</td>\n",
       "      <td>58</td>\n",
       "      <td>Steve Buchele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.249</td>\n",
       "      <td>54</td>\n",
       "      <td>Kal Daniels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2475</td>\n",
       "      <td>0.260</td>\n",
       "      <td>59</td>\n",
       "      <td>Shawon Dunston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>0.273</td>\n",
       "      <td>87</td>\n",
       "      <td>Mark Grace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary    AVG  Runs            Name\n",
       "0    3300  0.272    69    Andre Dawson\n",
       "1    2600  0.269    58   Steve Buchele\n",
       "2    2500  0.249    54     Kal Daniels\n",
       "3    2475  0.260    59  Shawon Dunston\n",
       "4    2313  0.273    87      Mark Grace"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millionaire_indices = baseball['Salary'] > 1000\n",
    "# you can use the query indices to look at a subset of your original dataframe\n",
    "print 'baseball.shape:', baseball.shape\n",
    "print \"baseball[millionaire_indices].shape:\", baseball[millionaire_indices].shape\n",
    "baseball[millionaire_indices][['Salary', 'AVG', 'Runs', 'Name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoe_size_df = pd.read_csv('data/baseball2.dat.txt')\n",
    "shoe_size_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Doubles</th>\n",
       "      <th>Triples</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>SO</th>\n",
       "      <th>SB</th>\n",
       "      <th>Errs</th>\n",
       "      <th>free agency eligibility</th>\n",
       "      <th>free agent in 1991/2</th>\n",
       "      <th>arbitration eligibility</th>\n",
       "      <th>arbitration in 1991/2</th>\n",
       "      <th>Name</th>\n",
       "      <th>Shoe Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.302</td>\n",
       "      <td>69</td>\n",
       "      <td>153</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Andre Dawson</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.346</td>\n",
       "      <td>87</td>\n",
       "      <td>169</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark Grace</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.240</td>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>14</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sammy Sosa</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary    AVG    OBP  Runs  Hits  Doubles  Triples  HR  RBI  Walks  SO  SB  \\\n",
       "0    3300  0.272  0.302    69   153       21        4  31  104     22  80   4   \n",
       "1    2313  0.273  0.346    87   169       28        5   8   58     70  53   3   \n",
       "2     200  0.203  0.240    39    64       10        1  10   33     14  96  13   \n",
       "\n",
       "   Errs  free agency eligibility  free agent in 1991/2  \\\n",
       "0     3                        1                     0   \n",
       "1     8                        0                     0   \n",
       "2     6                        0                     0   \n",
       "\n",
       "   arbitration eligibility  arbitration in 1991/2          Name  Shoe Size  \n",
       "0                        0                      0  Andre Dawson         11  \n",
       "1                        1                      0    Mark Grace         13  \n",
       "2                        0                      0    Sammy Sosa         12  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(baseball, shoe_size_df, on=['Name'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Doubles</th>\n",
       "      <th>Triples</th>\n",
       "      <th>HR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>SO</th>\n",
       "      <th>SB</th>\n",
       "      <th>Errs</th>\n",
       "      <th>free agency eligibility</th>\n",
       "      <th>free agent in 1991/2</th>\n",
       "      <th>arbitration eligibility</th>\n",
       "      <th>arbitration in 1991/2</th>\n",
       "      <th>Name</th>\n",
       "      <th>Shoe Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3300</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.302</td>\n",
       "      <td>69</td>\n",
       "      <td>153</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>104</td>\n",
       "      <td>22</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Andre Dawson</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.335</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>39</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Steve Buchele</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.337</td>\n",
       "      <td>54</td>\n",
       "      <td>115</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>116</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kal Daniels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2475</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.292</td>\n",
       "      <td>59</td>\n",
       "      <td>128</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shawon Dunston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.346</td>\n",
       "      <td>87</td>\n",
       "      <td>169</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>70</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark Grace</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary    AVG    OBP  Runs  Hits  Doubles  Triples  HR  RBI  Walks   SO  \\\n",
       "0    3300  0.272  0.302    69   153       21        4  31  104     22   80   \n",
       "1    2600  0.269  0.335    58   111       17        2  18   66     39   69   \n",
       "2    2500  0.249  0.337    54   115       15        1  17   73     63  116   \n",
       "3    2475  0.260  0.292    59   128       22        7  12   50     23   64   \n",
       "4    2313  0.273  0.346    87   169       28        5   8   58     70   53   \n",
       "\n",
       "   SB  Errs  free agency eligibility  free agent in 1991/2  \\\n",
       "0   4     3                        1                     0   \n",
       "1   0     3                        1                     1   \n",
       "2   6     5                        1                     0   \n",
       "3  21    21                        0                     0   \n",
       "4   3     8                        0                     0   \n",
       "\n",
       "   arbitration eligibility  arbitration in 1991/2            Name  Shoe Size  \n",
       "0                        0                      0    Andre Dawson         11  \n",
       "1                        0                      0   Steve Buchele        NaN  \n",
       "2                        0                      0     Kal Daniels        NaN  \n",
       "3                        1                      0  Shawon Dunston        NaN  \n",
       "4                        1                      0      Mark Grace         13  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_outer = pd.merge(baseball, shoe_size_df, on=['Name'], how='outer')\n",
    "merged_outer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.dat.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1EAAAHUCAYAAADbZ6LoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZI6MERJkiRJUgf/P4i8XEf4hMUmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x9550ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure()\n",
    "plt.hist(baseball['Hits'], bins=15)   # plot or scatter\n",
    "plt.xlabel('Number of Hits')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Number of Hits')\n",
    "f.set_size_inches(10, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sci-Kit Learn Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## linear regression models\n",
    "model_lr = linear_model.LinearRegression()\n",
    "model_ridge = linear_model.Ridge(alpha=1)\n",
    "model_lasso = linear_model.Lasso(alpha=1)\n",
    "model_en = linear_model.ElasticNet(alpha=0.5, l1_ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate the mean_squared_error given a vector of true ys and a vector of predicted ys\n",
    "    \"\"\"\n",
    "    diff = y_true - y_pred\n",
    "    return np.dot(diff, diff) / len(diff)\n",
    "\n",
    "def predict_test_values(model, X_train, y_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "    \n",
    "\n",
    "def calc_train_and_test_error(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    return mean_squared_error(y_train, y_pred_train), mean_squared_error(y_test, y_pred_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load overfitting data\n",
    "with np.load('data/overfitting_data.npz') as data:\n",
    "    x_train = data['x_train']\n",
    "    y_train = data['y_train']\n",
    "    x_test = data['x_test']\n",
    "    y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training and Test Errors:\n",
      "(2.4835421623899702e-05, 283.52728792173116)\n",
      "\n",
      "Ridge Regression Training and Test Errors:\n",
      "(0.018634112597992421, 9.5641560683730305)\n",
      "\n",
      "Lasso Regression Training and Test Errors:\n",
      "(4.1142351854727677, 4.6028697944107098)\n",
      "\n",
      "ElasticNet Errors:\n",
      "(1.9616145613107794, 3.8189893038857918)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Model performance\n",
    "\n",
    "print \"Linear Regression Training and Test Errors:\"\n",
    "print calc_train_and_test_error(model_lr, x_train, y_train, x_test, y_test)\n",
    "print\n",
    "\n",
    "print \"Ridge Regression Training and Test Errors:\"\n",
    "print calc_train_and_test_error(model_ridge, x_train, y_train, x_test, y_test)\n",
    "print\n",
    "\n",
    "print \"Lasso Regression Training and Test Errors:\"\n",
    "print calc_train_and_test_error(model_lasso, x_train, y_train, x_test, y_test)\n",
    "print\n",
    "\n",
    "print 'ElasticNet Training and Test Errors:'\n",
    "print calc_train_and_test_error(model_en, x_train, y_train, x_test, y_test)\n",
    "print \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Coefficients:\n",
      "[  5.22757470e-01   2.78289824e+00   4.04383818e+00   1.17544241e+00\n",
      "   3.13230537e-01  -1.28127160e-01   5.11682173e-01   3.83754833e-03\n",
      "  -1.19481096e+00   9.56448172e-01]\n",
      "\n",
      "Ridge Regression Coefficients:\n",
      "[ 1.01611626  1.77246927  3.06534773 -0.0333898   0.04378713  0.10472107\n",
      " -0.13445823  0.12656315  0.05779722  0.10204281]\n",
      "\n",
      "LASSO Coefficients:\n",
      "[ 0.03375129  0.92694409  1.92659636  0.          0.          0.         -0.\n",
      "  0.          0.          0.        ]\n",
      "\n",
      "ElasticNet Coefficients:\n",
      "[ 0.61034977  1.16675401  1.79600624  0.          0.          0.00686607\n",
      "  0.          0.02027936  0.00469244  0.00644604]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_disp_coefs = 10\n",
    "\n",
    "print 'Linear Regression Coefficients:'\n",
    "print model_lr.coef_[:n_disp_coefs]\n",
    "print\n",
    "\n",
    "print 'Ridge Regression Coefficients:'\n",
    "print model_ridge.coef_[:n_disp_coefs]\n",
    "print\n",
    "\n",
    "print 'LASSO Coefficients:'\n",
    "print model_lasso.coef_[:n_disp_coefs]\n",
    "print\n",
    "\n",
    "print 'ElasticNet Coefficients:'\n",
    "print model_en.coef_[:n_disp_coefs]\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Linear Regression Coefficients:\n",
      "338.387469048\n",
      "\n",
      "Sum of Ridge Regression Coefficients:\n",
      "62.4912904062\n",
      "\n",
      "Sum of Lasso Regression Coefficients:\n",
      "2.88729174216\n",
      "\n",
      "Sum of ElasticNet Coefficients\n",
      "9.82525057342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Sum of Linear Regression Coefficients:\"\n",
    "print np.sum(np.abs(model_lr.coef_))\n",
    "print\n",
    "\n",
    "print \"Sum of Ridge Regression Coefficients:\"\n",
    "print np.sum(np.abs(model_ridge.coef_))\n",
    "print\n",
    "\n",
    "print \"Sum of Lasso Regression Coefficients:\"\n",
    "print np.sum(np.abs(model_lasso.coef_))\n",
    "print\n",
    "\n",
    "print 'Sum of ElasticNet Coefficients'\n",
    "print np.sum(np.abs(model_en.coef_))\n",
    "print \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Cross Validation\n",
    "### Validation Set Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Set Size:\n",
      "(600L, 598L) (600L,)\n",
      "\n",
      "Reducted Training Set Size:\n",
      "(540L, 598L) (540L,)\n",
      "\n",
      "Validation Set Size:\n",
      "(60L, 598L) (60L,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a helper function for performing validation set cross validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "validation_portion = 0.1\n",
    "seed = 1234\n",
    "x_train_small, x_valid, y_train_small, y_valid = \\\n",
    "    train_test_split(x_train, y_train, test_size=validation_portion, random_state=seed)\n",
    "\n",
    "print 'Original Training Set Size:'\n",
    "print x_train.shape, y_train.shape\n",
    "print\n",
    "\n",
    "print 'Reducted Training Set Size:'\n",
    "print x_train_small.shape, y_train_small.shape\n",
    "print\n",
    "\n",
    "print 'Validation Set Size:'\n",
    "print x_valid.shape, y_valid.shape\n",
    "print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training and Test Errors:\n",
      "(6.5894013208313341e-28, 9.6373710755996189)\n",
      "\n",
      "Linear Regression Validation Errors:\n",
      "9.36759564041\n",
      "\n",
      "10.4039988935\n",
      "\n",
      "11.6352333478\n",
      "\n",
      "8.8241606146\n",
      "\n",
      "9.20945551949\n",
      "\n",
      "7.60088829288\n",
      "\n",
      "Ridge Regression Training and Test Errors:\n",
      "(0.037116269305341815, 4.8163269566646871)\n",
      "\n",
      "Ridge Regression Validation Errors:\n",
      "4.44120540399\n",
      "\n",
      "3.61817500364\n",
      "\n",
      "7.12476980873\n",
      "\n",
      "5.32580668571\n",
      "\n",
      "5.74292650031\n",
      "\n",
      "4.6239411424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def validation_set_error(model, x_train, y_train, validation_portion=0.1, seed=1234):\n",
    "    # FILL IN YOUR CODE HERE\n",
    "\n",
    "    x_train_small, x_valid, y_train_small, y_valid = \\\n",
    "        train_test_split(x_train, y_train, test_size=validation_portion, random_state=seed)\n",
    "    model.fit(x_train_small, y_train_small)\n",
    "    y_pred_valid = model.predict(x_valid)\n",
    "    return mean_squared_error(y_valid, y_pred_valid)\n",
    "      \n",
    "    \n",
    "# set up models\n",
    "model_lr_valid = linear_model.LinearRegression()\n",
    "model_ridge_valid = linear_model.Ridge(alpha=10)\n",
    "\n",
    "# calculate errors\n",
    "valid_portion = .1\n",
    "n_seeds = 5\n",
    "print \"Linear Regression Training and Test Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print calc_train_and_test_error(model_lr_valid, x_train_small, y_train_small, x_test, y_test)\n",
    "\n",
    "print\n",
    "print \"Linear Regression Validation Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print validation_set_error(model_lr_valid, x_train, y_train, validation_portion=0.1, seed=1234)\n",
    "print \n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    print validation_set_error(model_lr_valid, x_train, y_train, validation_portion=valid_portion, seed=seed)\n",
    "    print\n",
    "\n",
    "print \"Ridge Regression Training and Test Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print calc_train_and_test_error(model_ridge_valid, x_train_small, y_train_small, x_test, y_test)\n",
    "\n",
    "\n",
    "print\n",
    "print \"Ridge Regression Validation Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print validation_set_error(model_ridge_valid, x_train, y_train, validation_portion=0.1, seed=1234)\n",
    "print \n",
    "\n",
    "for seed in range(n_seeds):\n",
    "    print validation_set_error(model_ridge_valid, x_train, y_train, validation_portion=valid_portion, seed=seed)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scikit learn provides a useful object to help you perform kfold cross validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "n_data = len(y_train)\n",
    "fold_count = 0\n",
    "for train_reduced_row_ids, valid_row_ids in KFold(n_data, n_folds=4):\n",
    "    print\n",
    "    print \n",
    "    print \"FOLD %d:\" % fold_count\n",
    "    print \"-------\"\n",
    "    print(\"train_ids:\\n%s\\n\\nvalid_ids\\n%s\" % (train_reduced_row_ids, valid_row_ids))\n",
    "    x_train_reduced = x_train[train_reduced_row_ids]\n",
    "    y_train_reduced = y_train[train_reduced_row_ids]\n",
    "    x_valid = x_train[valid_row_ids]\n",
    "    y_valid = y_train[valid_row_ids]\n",
    "    fold_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: KFolds isn't random at all.  It's important to shuffle your data first before using it. \n",
    "from sklearn.utils import shuffle\n",
    "x_train_shuffled, y_train_shuffled = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Training and Test Errors:\n",
      "(2.4835421623899702e-05, 283.52728792173116)\n",
      "\n",
      "Linear Regression K-Fold Errors:\n",
      "\n",
      "7.21045028087\n",
      "\n",
      "7.3510411941\n",
      "\n",
      "6.69216918868\n",
      "\n",
      "\n",
      "Ridge Regression Training and Test Errors:\n",
      "(0.064063243432624289, 4.9205415455726982)\n",
      "\n",
      "Ridge Regression K-Fold Errors:\n",
      "\n",
      "5.77769677178\n",
      "\n",
      "5.78170553945\n",
      "\n",
      "5.6587338965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def kfold_error(model, x_train, y_train, k=4, seed=1234):\n",
    "    # FILL IN YOUR CODE HERE\n",
    "    \n",
    "    # shuffle training data\n",
    "    x_train_shuffled, y_train_shuffled = shuffle(x_train, y_train, random_state=seed)\n",
    "    \n",
    "    n_data = len(y_train)\n",
    "    error_sum = 0\n",
    "    for train_reduced_row_ids, valid_row_ids in KFold(n_data, n_folds=k):\n",
    "        x_train_reduced = x_train_shuffled[train_reduced_row_ids]\n",
    "        y_train_reduced = y_train_shuffled[train_reduced_row_ids]\n",
    "        x_valid = x_train_shuffled[valid_row_ids]\n",
    "        y_valid = y_train_shuffled[valid_row_ids]\n",
    "        model.fit(x_train_reduced, y_train_reduced)\n",
    "        y_valid_pred = model.predict(x_valid)\n",
    "        error_sum += mean_squared_error(y_valid, y_valid_pred)\n",
    "    return error_sum*1.0 / k\n",
    "    \n",
    "\n",
    "# set up models\n",
    "model_lr_valid = linear_model.LinearRegression()\n",
    "model_ridge_valid = linear_model.Ridge(alpha=10)\n",
    "\n",
    "# calculate errors\n",
    "n_seeds = 3\n",
    "k = 5\n",
    "\n",
    "print \"Linear Regression Training and Test Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print calc_train_and_test_error(model_lr_valid, x_train, y_train, x_test, y_test)\n",
    "\n",
    "print\n",
    "print \"Linear Regression K-Fold Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print \n",
    "for seed in range(n_seeds):\n",
    "    print kfold_error(model_lr_valid, x_train, y_train, k=k, seed=seed)\n",
    "    print \n",
    "\n",
    "print\n",
    "print \"Ridge Regression Training and Test Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print calc_train_and_test_error(model_ridge_valid, x_train, y_train, x_test, y_test)\n",
    "\n",
    "\n",
    "print\n",
    "print \"Ridge Regression K-Fold Errors:\"\n",
    "# FILL IN YOUR CODE HERE\n",
    "print \n",
    "for seed in range(n_seeds):\n",
    "    print kfold_error(model_ridge_valid, x_train, y_train, k=k, seed=seed)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Hyperparameter Selection with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beta 0</th>\n",
       "      <th>Beta 1</th>\n",
       "      <th>Beta 2</th>\n",
       "      <th>Beta 3</th>\n",
       "      <th>Beta 4</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Cross Validation Error</th>\n",
       "      <th>Test Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Coefs</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.522757</td>\n",
       "      <td>2.782898</td>\n",
       "      <td>4.043838</td>\n",
       "      <td>1.175442</td>\n",
       "      <td>0.313231</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.550726</td>\n",
       "      <td>8.569427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge(a=0.01)</th>\n",
       "      <td>0.867059</td>\n",
       "      <td>2.290546</td>\n",
       "      <td>3.729941</td>\n",
       "      <td>0.570987</td>\n",
       "      <td>0.380292</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>6.590630</td>\n",
       "      <td>8.592261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge(a=0.03)</th>\n",
       "      <td>1.028546</td>\n",
       "      <td>2.023949</td>\n",
       "      <td>3.548358</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>0.370161</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>6.588766</td>\n",
       "      <td>8.590441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge(a=0.1)</th>\n",
       "      <td>1.088696</td>\n",
       "      <td>1.847044</td>\n",
       "      <td>3.386562</td>\n",
       "      <td>0.012841</td>\n",
       "      <td>0.272410</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>6.582288</td>\n",
       "      <td>8.584100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge(a=0.3)</th>\n",
       "      <td>1.065763</td>\n",
       "      <td>1.788885</td>\n",
       "      <td>3.247394</td>\n",
       "      <td>-0.050784</td>\n",
       "      <td>0.142292</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>6.564170</td>\n",
       "      <td>8.566235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge(a=1)</th>\n",
       "      <td>1.016116</td>\n",
       "      <td>1.772469</td>\n",
       "      <td>3.065348</td>\n",
       "      <td>-0.033390</td>\n",
       "      <td>0.043787</td>\n",
       "      <td>0.018634</td>\n",
       "      <td>6.504991</td>\n",
       "      <td>8.506474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso(a=0.01)</th>\n",
       "      <td>1.076240</td>\n",
       "      <td>1.956283</td>\n",
       "      <td>2.955116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.213388</td>\n",
       "      <td>1.701747</td>\n",
       "      <td>1.849997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso(a=0.03)</th>\n",
       "      <td>1.042435</td>\n",
       "      <td>1.941418</td>\n",
       "      <td>2.952131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.526780</td>\n",
       "      <td>1.223279</td>\n",
       "      <td>1.196381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso(a=0.1)</th>\n",
       "      <td>0.972258</td>\n",
       "      <td>1.869852</td>\n",
       "      <td>2.892761</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.968836</td>\n",
       "      <td>1.024546</td>\n",
       "      <td>0.895046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso(a=0.3)</th>\n",
       "      <td>0.764523</td>\n",
       "      <td>1.659750</td>\n",
       "      <td>2.677197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.235803</td>\n",
       "      <td>1.264843</td>\n",
       "      <td>1.120443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso(a=1)</th>\n",
       "      <td>0.033751</td>\n",
       "      <td>0.926944</td>\n",
       "      <td>1.926596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.114235</td>\n",
       "      <td>4.166927</td>\n",
       "      <td>4.301203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.01, r=0.9)</th>\n",
       "      <td>1.073393</td>\n",
       "      <td>1.951365</td>\n",
       "      <td>2.947436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027348</td>\n",
       "      <td>0.195976</td>\n",
       "      <td>1.760720</td>\n",
       "      <td>1.935114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.01, r=0.7)</th>\n",
       "      <td>1.066012</td>\n",
       "      <td>1.936668</td>\n",
       "      <td>2.931448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031150</td>\n",
       "      <td>0.163034</td>\n",
       "      <td>1.919308</td>\n",
       "      <td>2.167257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.01, r=0.5)</th>\n",
       "      <td>1.046440</td>\n",
       "      <td>1.907626</td>\n",
       "      <td>2.908069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029275</td>\n",
       "      <td>0.127897</td>\n",
       "      <td>2.191965</td>\n",
       "      <td>2.583608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.03, r=0.9)</th>\n",
       "      <td>1.042974</td>\n",
       "      <td>1.931661</td>\n",
       "      <td>2.936235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008043</td>\n",
       "      <td>0.484044</td>\n",
       "      <td>1.261913</td>\n",
       "      <td>1.240859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.03, r=0.7)</th>\n",
       "      <td>1.038972</td>\n",
       "      <td>1.908386</td>\n",
       "      <td>2.901951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.401288</td>\n",
       "      <td>1.361827</td>\n",
       "      <td>1.360261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.03, r=0.5)</th>\n",
       "      <td>1.026654</td>\n",
       "      <td>1.885132</td>\n",
       "      <td>2.862618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020993</td>\n",
       "      <td>0.316085</td>\n",
       "      <td>1.547012</td>\n",
       "      <td>1.592804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.1, r=0.9)</th>\n",
       "      <td>0.971808</td>\n",
       "      <td>1.860572</td>\n",
       "      <td>2.872529</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960364</td>\n",
       "      <td>1.041134</td>\n",
       "      <td>0.906070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.1, r=0.7)</th>\n",
       "      <td>0.968971</td>\n",
       "      <td>1.841385</td>\n",
       "      <td>2.828162</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>1.092529</td>\n",
       "      <td>0.967566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.1, r=0.5)</th>\n",
       "      <td>0.961790</td>\n",
       "      <td>1.813670</td>\n",
       "      <td>2.765941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807426</td>\n",
       "      <td>1.215067</td>\n",
       "      <td>1.092389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.3, r=0.9)</th>\n",
       "      <td>0.771897</td>\n",
       "      <td>1.639918</td>\n",
       "      <td>2.624446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.277930</td>\n",
       "      <td>1.307354</td>\n",
       "      <td>1.168137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.3, r=0.7)</th>\n",
       "      <td>0.785336</td>\n",
       "      <td>1.603633</td>\n",
       "      <td>2.528307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.370249</td>\n",
       "      <td>1.400441</td>\n",
       "      <td>1.273228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=0.3, r=0.5)</th>\n",
       "      <td>0.797276</td>\n",
       "      <td>1.571245</td>\n",
       "      <td>2.442910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.469114</td>\n",
       "      <td>1.512212</td>\n",
       "      <td>1.390285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=1, r=0.9)</th>\n",
       "      <td>0.125708</td>\n",
       "      <td>0.934637</td>\n",
       "      <td>1.835475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.112881</td>\n",
       "      <td>4.189787</td>\n",
       "      <td>4.313581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=1, r=0.7)</th>\n",
       "      <td>0.265489</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>1.698143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.168660</td>\n",
       "      <td>4.233218</td>\n",
       "      <td>4.410287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet(a=1, r=0.5)</th>\n",
       "      <td>0.366721</td>\n",
       "      <td>0.954115</td>\n",
       "      <td>1.599575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.252089</td>\n",
       "      <td>4.309107</td>\n",
       "      <td>4.534828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Beta 0    Beta 1    Beta 2    Beta 3    Beta 4  \\\n",
       "True Coefs                 1.000000  2.000000  3.000000  0.000000  0.000000   \n",
       "LinearRegression           0.522757  2.782898  4.043838  1.175442  0.313231   \n",
       "Ridge(a=0.01)              0.867059  2.290546  3.729941  0.570987  0.380292   \n",
       "Ridge(a=0.03)              1.028546  2.023949  3.548358  0.237767  0.370161   \n",
       "Ridge(a=0.1)               1.088696  1.847044  3.386562  0.012841  0.272410   \n",
       "Ridge(a=0.3)               1.065763  1.788885  3.247394 -0.050784  0.142292   \n",
       "Ridge(a=1)                 1.016116  1.772469  3.065348 -0.033390  0.043787   \n",
       "Lasso(a=0.01)              1.076240  1.956283  2.955116  0.000000  0.025530   \n",
       "Lasso(a=0.03)              1.042435  1.941418  2.952131  0.000000  0.002460   \n",
       "Lasso(a=0.1)               0.972258  1.869852  2.892761 -0.000000  0.000000   \n",
       "Lasso(a=0.3)               0.764523  1.659750  2.677197  0.000000  0.000000   \n",
       "Lasso(a=1)                 0.033751  0.926944  1.926596  0.000000  0.000000   \n",
       "ElasticNet(a=0.01, r=0.9)  1.073393  1.951365  2.947436  0.000000  0.027348   \n",
       "ElasticNet(a=0.01, r=0.7)  1.066012  1.936668  2.931448  0.000000  0.031150   \n",
       "ElasticNet(a=0.01, r=0.5)  1.046440  1.907626  2.908069  0.000000  0.029275   \n",
       "ElasticNet(a=0.03, r=0.9)  1.042974  1.931661  2.936235  0.000000  0.008043   \n",
       "ElasticNet(a=0.03, r=0.7)  1.038972  1.908386  2.901951  0.000000  0.014723   \n",
       "ElasticNet(a=0.03, r=0.5)  1.026654  1.885132  2.862618  0.000000  0.020993   \n",
       "ElasticNet(a=0.1, r=0.9)   0.971808  1.860572  2.872529 -0.000000  0.000000   \n",
       "ElasticNet(a=0.1, r=0.7)   0.968971  1.841385  2.828162 -0.000000  0.000000   \n",
       "ElasticNet(a=0.1, r=0.5)   0.961790  1.813670  2.765941  0.000000  0.000000   \n",
       "ElasticNet(a=0.3, r=0.9)   0.771897  1.639918  2.624446  0.000000  0.000000   \n",
       "ElasticNet(a=0.3, r=0.7)   0.785336  1.603633  2.528307  0.000000  0.000000   \n",
       "ElasticNet(a=0.3, r=0.5)   0.797276  1.571245  2.442910  0.000000  0.000000   \n",
       "ElasticNet(a=1, r=0.9)     0.125708  0.934637  1.835475  0.000000  0.000000   \n",
       "ElasticNet(a=1, r=0.7)     0.265489  0.946058  1.698143  0.000000  0.000000   \n",
       "ElasticNet(a=1, r=0.5)     0.366721  0.954115  1.599575  0.000000  0.000000   \n",
       "\n",
       "                           Train Error  Cross Validation Error  Test Error  \n",
       "True Coefs                         NaN                     NaN         NaN  \n",
       "LinearRegression              0.000025                6.550726    8.569427  \n",
       "Ridge(a=0.01)                 0.001033                6.590630    8.592261  \n",
       "Ridge(a=0.03)                 0.002749                6.588766    8.590441  \n",
       "Ridge(a=0.1)                  0.005693                6.582288    8.584100  \n",
       "Ridge(a=0.3)                  0.010186                6.564170    8.566235  \n",
       "Ridge(a=1)                    0.018634                6.504991    8.506474  \n",
       "Lasso(a=0.01)                 0.213388                1.701747    1.849997  \n",
       "Lasso(a=0.03)                 0.526780                1.223279    1.196381  \n",
       "Lasso(a=0.1)                  0.968836                1.024546    0.895046  \n",
       "Lasso(a=0.3)                  1.235803                1.264843    1.120443  \n",
       "Lasso(a=1)                    4.114235                4.166927    4.301203  \n",
       "ElasticNet(a=0.01, r=0.9)     0.195976                1.760720    1.935114  \n",
       "ElasticNet(a=0.01, r=0.7)     0.163034                1.919308    2.167257  \n",
       "ElasticNet(a=0.01, r=0.5)     0.127897                2.191965    2.583608  \n",
       "ElasticNet(a=0.03, r=0.9)     0.484044                1.261913    1.240859  \n",
       "ElasticNet(a=0.03, r=0.7)     0.401288                1.361827    1.360261  \n",
       "ElasticNet(a=0.03, r=0.5)     0.316085                1.547012    1.592804  \n",
       "ElasticNet(a=0.1, r=0.9)      0.960364                1.041134    0.906070  \n",
       "ElasticNet(a=0.1, r=0.7)      0.913444                1.092529    0.967566  \n",
       "ElasticNet(a=0.1, r=0.5)      0.807426                1.215067    1.092389  \n",
       "ElasticNet(a=0.3, r=0.9)      1.277930                1.307354    1.168137  \n",
       "ElasticNet(a=0.3, r=0.7)      1.370249                1.400441    1.273228  \n",
       "ElasticNet(a=0.3, r=0.5)      1.469114                1.512212    1.390285  \n",
       "ElasticNet(a=1, r=0.9)        4.112881                4.189787    4.313581  \n",
       "ElasticNet(a=1, r=0.7)        4.168660                4.233218    4.410287  \n",
       "ElasticNet(a=1, r=0.5)        4.252089                4.309107    4.534828  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_name(model):\n",
    "    s = model.__str__().lower()\n",
    "    if \"linearregression\" in s:\n",
    "        return 'LinearRegression'\n",
    "    elif \"lasso\" in s:\n",
    "        return 'Lasso(a=%g)' % model.alpha\n",
    "    elif \"ridge\" in s:\n",
    "        return 'Ridge(a=%g)' % model.alpha\n",
    "    elif \"elastic\" in s:\n",
    "        return 'ElasticNet(a=%g, r=%g)' % (model.alpha, model.l1_ratio)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model Type\")\n",
    "\n",
    "def create_models(alphas=(.01, .03, .1, .3, 1, 3), l1_ratios=(.7, .5, .3)):\n",
    "    models = [linear_model.LinearRegression()]\n",
    "    models.extend([linear_model.Ridge(a) for a in alphas])\n",
    "    models.extend([linear_model.Lasso(a) for a in alphas])\n",
    "    models.extend([linear_model.ElasticNet(a, l1_ratio=l) for a in alphas for l in l1_ratios])\n",
    "    return models\n",
    "\n",
    "def results_df(models, betas_true, x_train, y_train, x_test, y_test, k=4):\n",
    "    n_data, n_dim = x_train.shape\n",
    "\n",
    "    n_zeros = n_dim - len(betas_true)\n",
    "    \n",
    "    betas_true = np.concatenate([betas_true, np.zeros(n_zeros)])\n",
    "    \n",
    "    # fit models to training data\n",
    "    [m.fit(x_train, y_train) for m in models]\n",
    "    \n",
    "    betas = np.vstack([betas_true] + [m.coef_ for m in models])\n",
    "    beta_names = ['Beta ' + str(i) for i in range(n_dim)]\n",
    "\n",
    "    # set up model names\n",
    "    model_names =  [\"True Coefs\"] + [model_name(m) for m in models]\n",
    "    df = pd.DataFrame(data=betas, columns=beta_names, index=model_names)\n",
    "\n",
    "    # calculate training errors\n",
    "    y_preds = [m.predict(x_train) for m in models]\n",
    "    errors = [np.nan] + [mean_squared_error(y_train, y_pred) for y_pred in y_preds]\n",
    "    df['Train Error'] = errors\n",
    "\n",
    "    # calculate validation errors\n",
    "    errors = [np.nan] + [kfold_error(m, x_train, y_train, k=k) for m in models]\n",
    "    df['Cross Validation Error'] = errors\n",
    "\n",
    "    # calculate test errors\n",
    "    y_preds = [m.predict(x_test) for m in models]\n",
    "    errors = [np.nan] + [mean_squared_error(y_test, y_pred) for y_pred in y_preds]\n",
    "    df['Test Error'] = errors\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# these are some of the magic parameters that I used to actually \n",
    "# generate the overfitting dataset\n",
    "n_dim = 598\n",
    "n_dim_meaningful = 3\n",
    "n_dim_disp_extra = 2\n",
    "\n",
    "# the actual betas used to generate the y values.  the rest were 0.\n",
    "betas_true = np.arange(n_dim_meaningful) + 1\n",
    "\n",
    "# create a whole bunch of untrained models\n",
    "models = create_models(alphas=(.01, .03, .1, .3, 1), l1_ratios=(.9, .7, .5))\n",
    "\n",
    "# \n",
    "all_results = results_df(models, betas_true, x_train, y_train, x_test, y_test, k=4)\n",
    "\n",
    "# decide which columns we want to display\n",
    "disp_cols = [\"Beta \" + str(i) for i in range(n_dim_meaningful + n_dim_disp_extra)] \n",
    "disp_cols += ['Train Error', 'Cross Validation Error', 'Test Error']\n",
    "\n",
    "# display the results\n",
    "all_results[disp_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scikit learn includes some functions for making cross validation easier \n",
    "# and computationally faster for a some models\n",
    "from sklearn import linear_model\n",
    "model_ridge_cv = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0])\n",
    "model_lasso_cv = linear_model.LassoCV(alphas=[0.1, 1.0, 10.0])\n",
    "model_en_cv = linear_model.ElasticNetCV(l1_ratio=[.9], n_alphas=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
